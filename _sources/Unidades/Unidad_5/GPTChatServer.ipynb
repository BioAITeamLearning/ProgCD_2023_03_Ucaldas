{"cells":[{"cell_type":"markdown","metadata":{"id":"DUpqrlXpV5Ln"},"source":["# GPTChatServer"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9019,"status":"ok","timestamp":1693782206087,"user":{"displayName":"REINEL TABARES SOTO","userId":"06191532127423773923"},"user_tz":300},"id":"VQw9jiqbRIyQ","outputId":"aa994218-35ed-46a0-dc97-4b7ee3385bd6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openai\n","  Using cached openai-0.28.1-py3-none-any.whl (76 kB)\n","Requirement already satisfied: requests>=2.20 in c:\\python311\\lib\\site-packages (from openai) (2.28.2)\n","Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from openai) (4.66.1)\n","Collecting aiohttp\n","  Using cached aiohttp-3.8.6-cp311-cp311-win_amd64.whl (322 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests>=2.20->openai) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\python311\\lib\\site-packages (from aiohttp->openai) (22.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Using cached multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n","Collecting yarl<2.0,>=1.0\n","  Using cached yarl-1.9.2-cp311-cp311-win_amd64.whl (60 kB)\n","Collecting frozenlist>=1.1.1\n","  Using cached frozenlist-1.4.0-cp311-cp311-win_amd64.whl (44 kB)\n","Collecting aiosignal>=1.1.2\n","  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm->openai) (0.4.6)\n","Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n"]},{"name":"stderr","output_type":"stream","text":["  WARNING: Failed to write executable - trying to use .deleteme logic\n","ERROR: Could not install packages due to an OSError: [WinError 2] El sistema no puede encontrar el archivo especificado: 'C:\\\\Python311\\\\Scripts\\\\openai.exe' -> 'C:\\\\Python311\\\\Scripts\\\\openai.exe.deleteme'\n","\n","\n","[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install openai "]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uqm6tfaBV5Lq","outputId":"6d864464-4e7c-45d6-dd78-69399e947ff8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Esperando una conexi贸n...\n","Conexi贸n desde ('127.0.0.1', 50374)\n"]},{"ename":"RateLimitError","evalue":"You exceeded your current quota, please check your plan and billing details.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32md:\\Reinel\\Cursos_Ingenieria_Sistemas_UCaldas_2023_3\\PCyD\\Unidades\\Unidad_5\\GPTChatServer.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m pregunta \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# obtenemos la respuesta del chatbot GPT\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m respuesta \u001b[39m=\u001b[39m obtener_respuesta_gpt(pregunta)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# enviamos la respuesta al cliente\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m conn\u001b[39m.\u001b[39msendall(respuesta\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n","\u001b[1;32md:\\Reinel\\Cursos_Ingenieria_Sistemas_UCaldas_2023_3\\PCyD\\Unidades\\Unidad_5\\GPTChatServer.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobtener_respuesta_gpt\u001b[39m(mensaje):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-davinci-003\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         prompt\u001b[39m=\u001b[39;49mmensaje,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         max_tokens\u001b[39m=\u001b[39;49m\u001b[39m4000\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         n\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         stop\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0.7\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Reinel/Cursos_Ingenieria_Sistemas_UCaldas_2023_3/PCyD/Unidades/Unidad_5/GPTChatServer.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[0;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n","\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."]}],"source":["import socket\n","import openai\n","import os\n","\n","# Configurar la clave API de OpenAI\n","#openai.api_key = \"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\"\n","#openai.api_key = \"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\"\n","\n","openai.api_key = \"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\"\n","def obtener_respuesta_gpt(mensaje):\n","    response = openai.Completion.create(\n","        engine=\"text-davinci-003\",\n","        prompt=mensaje,\n","        max_tokens=4000,\n","        n=1,\n","        stop=None,\n","        temperature=0.7,\n","    )\n","    return response.choices[0].text.strip()\n","\n","# creamos un socket TCP/IP\n","sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n","\n","# especificamos la direccion y el puerto del servidor\n","server_address = ('localhost', 8070)\n","sock.bind(server_address)\n","sock.listen(1)\n","\n","print('Esperando una conexi贸n...')\n","conn, addr = sock.accept()\n","\n","try:\n","    print('Conexi贸n desde', addr)\n","\n","    while True:\n","        # recibimos la pregunta del cliente\n","        data = conn.recv(1024)\n","        if not data:\n","            break\n","        pregunta = data.decode('utf-8').strip()\n","\n","        # obtenemos la respuesta del chatbot GPT\n","        respuesta = obtener_respuesta_gpt(pregunta)\n","\n","        # enviamos la respuesta al cliente\n","        conn.sendall(respuesta.encode('utf-8'))\n","\n","finally:\n","    conn.close()\n","    sock.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!hostname -I"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"euUw3QGFRhrl"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
